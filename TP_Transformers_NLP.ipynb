{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a961ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./opt/anaconda3/lib/python3.8/site-packages (4.10.0.dev0)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in ./opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "zsh:1: no matches found: transformers[sentencepiece]\n",
      "Requirement already satisfied: transformers[sentencepiece] in ./opt/anaconda3/lib/python3.8/site-packages (4.10.0.dev0)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.0.45)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (1.20.3)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (2021.7.6)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (4.61.2)\n",
      "Requirement already satisfied: protobuf in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (3.17.2)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.1.91)\n",
      "Requirement already satisfied: typing-extensions in ./opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers[sentencepiece]) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers[sentencepiece]) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in ./opt/anaconda3/lib/python3.8/site-packages (from protobuf->transformers[sentencepiece]) (1.16.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (2021.5.30)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers[sentencepiece]) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "!conda install -c huggingface transformers\n",
    "!pip3 install transformers[sentencepiece]\n",
    "!pip3 install \"transformers[sentencepiece]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea076da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccdcb995",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b79544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "franch_txt=(\"\"\"\n",
    "             peut-être l'un des progrès les plus importants réalisés par les mathématiques arabes a commencé à cette époque\n",
    "             avec les travaux d'al-Khwarizmi, à savoir les débuts de l'algèbre. Il est important de\n",
    "             comprendre à quel point cette nouvelle idée était importante. C'était un éloignement révolutionnaire\n",
    "             du concept grec des mathématiques qui était essentiellement la géométrie. L'algèbre était un\n",
    "             théorie unificatrice qui permettait les nombres rationnels, les nombres irrationnels, les\n",
    "             grandeurs, etc., à tous être traités comme des \"objets algébriques\". Cela a donné aux mathématiques une toute nouvelle\n",
    "             voie de développement tellement plus large dans son concept que celle qui existait auparavant, et a fourni un\n",
    "             véhicule pour le développement futur du sujet. Un autre aspect important de l'introduction\n",
    "             des idées algébriques était qu'elle permettait aux mathématiques de s'appliquer à elles-mêmes d'une manière qui\n",
    "             n'était pas arrivé auparavant.\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62da17eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franch text :  {'input_ids': [101, 185, 14272, 1204, 118, 256, 7877, 181, 112, 8362, 3532, 5250, 1403, 1197, 10695, 8241, 4882, 1696, 1116, 187, 2744, 14200, 10051, 14247, 8241, 12523, 2744, 21943, 18853, 170, 17952, 1279, 170, 3254, 2354, 27891, 246, 172, 6347, 255, 5674, 3530, 170, 2707, 1665, 8241, 189, 1611, 2497, 5025, 173, 112, 2393, 118, 148, 24156, 28021, 3080, 117, 246, 21718, 6005, 3161, 8241, 173, 2744, 16442, 1116, 1260, 181, 112, 2393, 1403, 27113, 9730, 119, 9190, 12890, 1696, 1260, 3254, 1643, 5123, 11114, 246, 15027, 1233, 1553, 172, 6347, 1185, 19581, 4838, 25021, 8533, 255, 13564, 1204, 1696, 1162, 119, 140, 112, 255, 13564, 1204, 8362, 255, 2858, 11368, 14529, 187, 2744, 6005, 18404, 24730, 3840, 3400, 176, 1874, 1665, 3532, 12523, 2744, 21943, 18853, 186, 6592, 255, 13564, 1204, 13936, 27408, 10387, 20041, 2495, 176, 2744, 4165, 2744, 19091, 1162, 119, 149, 112, 2393, 1403, 27113, 9730, 255, 13564, 1204, 8362, 24438, 2744, 9012, 1162, 8362, 19814, 2980, 10835, 186, 6592, 1679, 23355, 21263, 8241, 1185, 20347, 1116, 6022, 10934, 3447, 117, 8241, 1185, 20347, 1116, 178, 10582, 2116, 8967, 1116, 117, 8241, 5372, 8816, 1116, 117, 3576, 119, 117, 246, 1106, 1361, 256, 7877, 20323, 10051, 3254, 3263, 3532, 107, 184, 1830, 18836, 1116, 2393, 21645, 27647, 11962, 107, 119, 24664, 1742, 170, 1274, 1179, 2744, 24544, 12523, 2744, 21943, 18853, 25731, 1106, 6140, 1185, 19581, 4838, 191, 8136, 1162, 1260, 173, 2744, 12559, 4184, 3186, 1880, 1587, 14529, 4882, 1415, 22463, 1488, 3400, 15027, 2765, 1162, 186, 6592, 4056, 21263, 12686, 17482, 21714, 1204, 117, 3084, 170, 1300, 2605, 8362, 191, 2744, 11239, 8722, 11480, 5837, 173, 2744, 12559, 4184, 3186, 1880, 175, 3818, 2149, 3840, 28117, 18836, 119, 12118, 12686, 7877, 7631, 1696, 1260, 181, 112, 4784, 3532, 25021, 21272, 2393, 21645, 27647, 11962, 255, 13564, 1204, 186, 1358, 112, 8468, 1513, 1679, 23355, 21263, 24544, 12523, 2744, 21943, 18853, 1260, 188, 112, 12647, 21492, 1197, 246, 8468, 2897, 118, 182, 24559, 6801, 173, 112, 25731, 1299, 19999, 186, 6592, 183, 112, 255, 13564, 1204, 185, 2225, 170, 14791, 1964, 2744, 12686, 17482, 21714, 1204, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(franch_txt)\n",
    "print(\"Franch text : \",encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc54a1",
   "metadata": {},
   "source": [
    "# text generation in franch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddcf103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a46d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"J'aime le football, mais j'aime plus le jeu de course. »Le premier match de la série est joué le 19 mai 2010 contre les Rangers de New York. Les deux équipes se rencontrent sur le score de deux buts à un. Les deux équipes se rencontrent sur le score de deux\"}]\n"
     ]
    }
   ],
   "source": [
    "franch_gen = pipeline('text-generation', model='dbddv01/gpt2-french-small')\n",
    "franch_txt_gen=(\"J'aime le football, mais j'aime plus\")\n",
    "\n",
    "\n",
    "\n",
    "print(franch_gen(franch_txt_gen, max_length=60, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88f05a",
   "metadata": {},
   "source": [
    "# text generation in Arabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f2d3d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ff1e7d23854f8aa370a691285bb663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49aee7048844b7e828d42bdec292067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da388bed9524327be0a0e302a05aec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0394af5898db42ee82064a4978c0d376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a73f2789d3f45948c148a8cda330079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'أنا أحب كرة القدم ، لكني أحب أكثر من مرة كرة القدم . في عام 2006 ، تم اختيار أفضل لاعب في العالم في بطولة العالم للشباب تحت 20 عاما. في عام 2007 ، تم اختيار أفضل لاعب في العالم في بطولة العالم للشباب تحت 20 عاما.'}]\n"
     ]
    }
   ],
   "source": [
    "arab_gen = pipeline('text-generation', model='akhooli/gpt2-small-arabic')\n",
    "arab_txt_gen=(\"أنا أحب كرة القدم ، لكني أحب أكثر\")\n",
    "\n",
    "\n",
    "\n",
    "print(arab_gen(arab_txt_gen, max_length=50, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302e782",
   "metadata": {},
   "source": [
    "# Text translation English to Frannch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c364e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b96a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "franch_translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99c808d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Translation : \n",
      "\n",
      "[{'translation_text': \"Pour acquérir des compétences dans une langue seconde, il faut comprendre le fonctionnement de la langue et prendre le temps de l'utiliser. ESL002 vous encourage à travailler avec de nouvelles idées grammaticales et de nouveaux choix de mots, et à vous servir de ces sujets pour vous écrire et élargir vos compétences en écriture.\"}]\n"
     ]
    }
   ],
   "source": [
    "englesh_txt=(\"\"\"\n",
    "            Developing skills in a second language involves understanding how the language works \n",
    "            and taking the time to practice using it. ESL002 encourages you to work with new \n",
    "            grammar ideas and word choices, and practice using those topics to write about yourself \n",
    "            and expand your writing skills.\n",
    "            \"\"\")\n",
    "\n",
    "\n",
    "print(\"Result of Translation : \\n\")\n",
    "\n",
    "#RESULT OF TRANSLATION\n",
    "\n",
    "print(franch_translator(englesh_txt, max_length=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0663968",
   "metadata": {},
   "source": [
    "# Text translation  Arabe to Frannch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d341908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dl-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dl_translate as dlt\n",
    "\n",
    "mt = dlt.TranslationModel()\n",
    "\n",
    "text_ar = (\"\"\"\n",
    "            يتضمن تطوير المهارات في لغة ثانية فهم كيفية عمل اللغة\n",
    "             وأخذ الوقت الكافي للتدرب على استخدامه. ESL002 يشجعك على العمل مع ملفات\n",
    "             الأفكار النحوية واختيار الكلمات ، وتدرب على استخدام تلك المواضيع في الكتابة عن نفسك\n",
    "             وتوسيع مهاراتك في الكتابة.\n",
    "             \"\"\")\n",
    "\n",
    "mt.translate(text_ar, source=\"Arabic\", target=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All languages that you can use\n",
    "print(mt.available_languages())  \n",
    "# Code corresponding to each language accepted\n",
    "print(mt.available_codes())  \n",
    "\n",
    "print(mt.get_lang_code_map())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5b54e",
   "metadata": {},
   "source": [
    "# Sentiment analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50101464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./opt/anaconda3/lib/python3.8/site-packages (4.10.0.dev0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in ./opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Collecting TensorFlow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-macosx_10_11_x86_64.whl (195.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 195.7 MB 233 kB/s eta 0:00:01    |██                              | 12.3 MB 284 kB/s eta 0:10:45     |████▎                           | 26.3 MB 424 kB/s eta 0:06:40     |█████▋                          | 34.6 MB 714 kB/s eta 0:03:46     |█████▊                          | 34.9 MB 329 kB/s eta 0:08:08     |██████▊                         | 41.2 MB 736 kB/s eta 0:03:30     |███████▉                        | 48.1 MB 95 kB/s eta 0:25:40     |████████                        | 49.4 MB 208 kB/s eta 0:11:41     |████████                        | 49.5 MB 208 kB/s eta 0:11:41     |████████▌                       | 52.2 MB 673 kB/s eta 0:03:33     |████████▌                       | 52.3 MB 673 kB/s eta 0:03:33     |██████████████▉                 | 91.0 MB 613 kB/s eta 0:02:51     |█████████████████▋              | 107.6 MB 375 kB/s eta 0:03:55     |█████████████████▉              | 108.8 MB 50 kB/s eta 0:28:33     |███████████████████             | 116.7 MB 209 kB/s eta 0:06:18     |███████████████████▍            | 118.6 MB 353 kB/s eta 0:03:38     |███████████████████▊            | 120.8 MB 379 kB/s eta 0:03:18     |████████████████████▍           | 124.6 MB 395 kB/s eta 0:03:00     |█████████████████████▏          | 129.7 MB 350 kB/s eta 0:03:09     |███████████████████████▍        | 143.2 MB 500 kB/s eta 0:01:45     |███████████████████████▍        | 143.3 MB 500 kB/s eta 0:01:45     |███████████████████████▋        | 144.5 MB 366 kB/s eta 0:02:20     |█████████████████████████       | 152.8 MB 150 kB/s eta 0:04:46     |█████████████████████████▎      | 154.4 MB 223 kB/s eta 0:03:05     |████████████████████████████▍   | 173.4 MB 379 kB/s eta 0:00:59     |██████████████████████████████▍ | 185.5 MB 636 kB/s eta 0:00:16     |██████████████████████████████▊ | 187.6 MB 261 kB/s eta 0:00:31     |███████████████████████████████ | 189.3 MB 591 kB/s eta 0:00:11     |███████████████████████████████▎| 191.0 MB 223 kB/s eta 0:00:21     |███████████████████████████████▉| 194.6 MB 679 kB/s eta 0:00:02\n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 395 kB/s eta 0:00:01     |██████▌                         | 1.2 MB 489 kB/s eta 0:00:10\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 300 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 642 kB/s eta 0:00:01     |███████████████████▏            | 747 kB 642 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in ./opt/anaconda3/lib/python3.8/site-packages (from TensorFlow) (1.12.1)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-macosx_10_10_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 344 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 330 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in ./opt/anaconda3/lib/python3.8/site-packages (from TensorFlow) (3.17.2)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in ./opt/anaconda3/lib/python3.8/site-packages (from TensorFlow) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 503 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 569 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 612 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 536 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 454 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 605 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->TensorFlow) (57.2.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 390 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 631 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->TensorFlow) (1.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->TensorFlow) (2.25.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 646 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 661 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 797 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=e6af0cfb39705ca421c955984bc9a1288ce3672fc18dabf375f62561b3734325\n",
      "  Stored in directory: /Users/danieljoaquimpaulino/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, six, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, TensorFlow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "ktrain 0.26.5 requires scikit-learn==0.23.2, but you have scikit-learn 0.24.2 which is incompatible.\n",
      "ktrain 0.26.5 requires transformers<=4.3.3,>=4.0.0, but you have transformers 4.10.0.dev0 which is incompatible.\n",
      "flair 0.8.0.post1 requires sentencepiece==0.1.95, but you have sentencepiece 0.1.91 which is incompatible.\u001b[0m\n",
      "Successfully installed TensorFlow-2.5.0 absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.34.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
      "Collecting HuggingFace\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: HuggingFace\n",
      "Successfully installed HuggingFace-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install TensorFlow\n",
    "!pip install HuggingFace\n",
    "\n",
    "from transformers import pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e20e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c879a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engl_text = nlp(\"I really like to read\")\n",
    "print(\"\\n\")\n",
    "print(engl_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
